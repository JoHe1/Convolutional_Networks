{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning usando VGG16\n",
    "\n",
    "Usando Transfer Learning, buscamos utilizar un modelo preentrenado para resolver un problema diferente al que fue entrenado originalmente. En este caso, utilizaremos la red VGG16 en el dataset sobre imagenes de animales, un dataset bastante pequeño, para comprobar los resultados que nos dan.\n",
    "\n",
    "La principal ventaja que nos aporta VGG16, es que como ya tiene los pesos ajustado es una gran herramientas para extraer características de las imagenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código\n",
    "### Librerías\n",
    "Las librerías que utilizaremos son las siguientes:\n",
    "- numpy: para el manejo de matrices\n",
    "- torch.nn: para la creación de la red neuronal\n",
    "- torch.optim: para la optimización de la red\n",
    "- torchvision import models: para la importación de la red VGG16\n",
    "- torchvision import datasets: para la importación del dataset\n",
    "- torchvision import transforms: para la transformación de las imagenes\n",
    "- torch.utils.data import DataLoader: para la creación de los dataloaders\n",
    "- torch.utils.data import random_split: para la división del dataset en entrenamiento y test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comprobación de la GPU\n",
    "Comprobamos si tenemos una GPU disponible para acelerar el entrenamiento de la red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos\n",
    "Primero adataremos los transformadores para las imagenes. Luego cargaremos el dataset de animales y crearemos los dataloaders para el entrenamiento y test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformaciones para redimensionar y normalizar las imágenes\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),    # Redimensionar a 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.4914, 0.4822, 0.4465],\n",
    "        std=[0.2023, 0.1994, 0.2010],\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 336\n",
      "Tamaño del conjunto de prueba: 85\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset completo\n",
    "dataset = datasets.ImageFolder(root='dataset_animales/animals/animals/', transform=transform)\n",
    "\n",
    "# Calcular las longitudes para entrenamiento y prueba (80% y 20%)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "# Dividir el dataset en entrenamiento y prueba\n",
    "train_data, test_data = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Crear DataLoaders para el conjunto de entrenamiento y prueba\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "# Verificación de tamaños\n",
    "print(\"Tamaño del conjunto de entrenamiento:\", len(train_loader.dataset))\n",
    "print(\"Tamaño del conjunto de prueba:\", len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de modelo VGG16\n",
    "Cargaremos el modelo VGG16 preetrenado y cambiaremos la última capa para adaptarla a nuestro problema. Determinaremos la cantidad de clases que tiene nuestro problema y usando model.classifier[6] = nn.Linear(4096, num_classes) cambiaremos la última capa de la red de la parte de classifier.\n",
    "\n",
    "Como conocemos la estructura de la red solo necesitaremos cambiar la última capa de la parte de clasificación ya que Torch nos permite acceder a las capas de la red de manera sencilla.\n",
    "\n",
    "Si quisieramos cambiar las partes convolucionales de la red, tendríamos que cambiar la parte de features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\Documents\\Ingenieria de Datos\\3_AÑO\\1_Semestre\\AA2\\Practicas\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Usuario\\Documents\\Ingenieria de Datos\\3_AÑO\\1_Semestre\\AA2\\Practicas\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo VGG16 preentrenado\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "# Cambiar la última capa fully connected para que coincida con el número de clases de tu dataset\n",
    "num_classes = len(dataset.classes)\n",
    "model.classifier[6] = nn.Linear(4096, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente imagen se muestra la estructura de la red VGG16:\n",
    "\n",
    "![VGG16](illu_VGG-02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moviendo el modelo a la GPU\n",
    "Movemos el modelo a la GPU si está disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mover el modelo a la GPU si está disponible\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento y Test\n",
    "Entrenaremos el modelo con un optimizador que será SGD y una función de pérdida que será CrossEntropyLoss.\n",
    "\n",
    "El SGD usará un learning rate de 0.001 y un momentum de 0.9. También, tomaremos los parametros del modelo y los pasaremos al optimizador usando model.parameters()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 1.7512\n",
      "Accuracy on the test set: 100.00%\n",
      "Epoch [2/3], Loss: 0.4545\n",
      "Accuracy on the test set: 98.82%\n",
      "Epoch [3/3], Loss: 0.0622\n",
      "Accuracy on the test set: 97.65%\n"
     ]
    }
   ],
   "source": [
    "# Definir la función de pérdida y el optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.005)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass y optimización\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n",
    "    # Evaluación en el conjunto de prueba\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy on the test set: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Futuras Mejoras\n",
    "Utilizar la congelación de las capas de feuatures (capas convolucionales) para que no se actualicen los pesos de estas capas y solo se actualicen los pesos de las capas de clasificación.\n",
    "\n",
    "Esto ayudaría a utilizar la red preentrenada para extraer mejores las caracteristicas de las imagen y solo entrenar las capas de clasificación."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
